{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week8_MLP_Quick_WalkThrough.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2SUBDA/Breakouts/blob/Week8/Week8_MLP_Quick_WalkThrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0zqqZwotK_2"
      },
      "source": [
        "# BASIC WALK THROUGH FOR FASHION-MNIST MLP\n",
        "# BASED ON SKLEARN TUTORIALS \n",
        "# ALTERNATIVE TO CREATING MLP MODEL THE OLD FASHIONED WAY\n",
        "\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhm5xXKytg76"
      },
      "source": [
        "# OBTAIN\n",
        "\n",
        "digits = datasets.load_digits()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZfbEMtFtr4X"
      },
      "source": [
        "# SCRUB\n",
        "# NORMALIZE INPUTS FROM RGB TO 0-1\n",
        "\n",
        "X = digits.data / 255\n",
        "y = digits.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XWy-mvFuQxf"
      },
      "source": [
        "# MODEL\n",
        "# Build basic model using MLP Classifier\n",
        "# Additional configurations available:  https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, alpha=1e-4, solver=\"adam\",\n",
        "                    verbose = 10, tol=1e-4, random_state=1, learning_rate_init=.1)\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHpS6DI-utYP",
        "outputId": "c6ba2593-6fda-4fb4-d34d-bb17835bb8a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# MODEL\n",
        "# FIT\n",
        "\n",
        "mlp.fit(X_train, y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.16590220\n",
            "Iteration 2, loss = 1.23173143\n",
            "Iteration 3, loss = 0.58644120\n",
            "Iteration 4, loss = 0.35242122\n",
            "Iteration 5, loss = 0.25859961\n",
            "Iteration 6, loss = 0.21296919\n",
            "Iteration 7, loss = 0.18493035\n",
            "Iteration 8, loss = 0.14931151\n",
            "Iteration 9, loss = 0.12830493\n",
            "Iteration 10, loss = 0.14637506\n",
            "Iteration 11, loss = 0.12458948\n",
            "Iteration 12, loss = 0.10750769\n",
            "Iteration 13, loss = 0.09793221\n",
            "Iteration 14, loss = 0.07278789\n",
            "Iteration 15, loss = 0.07274549\n",
            "Iteration 16, loss = 0.06881495\n",
            "Iteration 17, loss = 0.06414864\n",
            "Iteration 18, loss = 0.04873463\n",
            "Iteration 19, loss = 0.04847816\n",
            "Iteration 20, loss = 0.05129334\n",
            "Iteration 21, loss = 0.05003880\n",
            "Iteration 22, loss = 0.04548845\n",
            "Iteration 23, loss = 0.04128697\n",
            "Iteration 24, loss = 0.03270697\n",
            "Iteration 25, loss = 0.02856366\n",
            "Iteration 26, loss = 0.02644293\n",
            "Iteration 27, loss = 0.02606026\n",
            "Iteration 28, loss = 0.02441724\n",
            "Iteration 29, loss = 0.02181927\n",
            "Iteration 30, loss = 0.02227938\n",
            "Iteration 31, loss = 0.02464276\n",
            "Iteration 32, loss = 0.02003288\n",
            "Iteration 33, loss = 0.02155614\n",
            "Iteration 34, loss = 0.02157935\n",
            "Iteration 35, loss = 0.03033897\n",
            "Iteration 36, loss = 0.02835419\n",
            "Iteration 37, loss = 0.03250416\n",
            "Iteration 38, loss = 0.03115793\n",
            "Iteration 39, loss = 0.02234060\n",
            "Iteration 40, loss = 0.02590582\n",
            "Iteration 41, loss = 0.01761179\n",
            "Iteration 42, loss = 0.01861050\n",
            "Iteration 43, loss = 0.01985384\n",
            "Iteration 44, loss = 0.02025905\n",
            "Iteration 45, loss = 0.01874851\n",
            "Iteration 46, loss = 0.01236542\n",
            "Iteration 47, loss = 0.01332467\n",
            "Iteration 48, loss = 0.01180830\n",
            "Iteration 49, loss = 0.00976098\n",
            "Iteration 50, loss = 0.00856960\n",
            "Iteration 51, loss = 0.00822631\n",
            "Iteration 52, loss = 0.00797750\n",
            "Iteration 53, loss = 0.00869903\n",
            "Iteration 54, loss = 0.00757051\n",
            "Iteration 55, loss = 0.00714714\n",
            "Iteration 56, loss = 0.00684954\n",
            "Iteration 57, loss = 0.00680089\n",
            "Iteration 58, loss = 0.00663765\n",
            "Iteration 59, loss = 0.00678339\n",
            "Iteration 60, loss = 0.00662884\n",
            "Iteration 61, loss = 0.00633782\n",
            "Iteration 62, loss = 0.00637518\n",
            "Iteration 63, loss = 0.00623156\n",
            "Iteration 64, loss = 0.00628208\n",
            "Iteration 65, loss = 0.00675065\n",
            "Iteration 66, loss = 0.00670993\n",
            "Iteration 67, loss = 0.00612747\n",
            "Iteration 68, loss = 0.00634960\n",
            "Iteration 69, loss = 0.00583436\n",
            "Iteration 70, loss = 0.00577390\n",
            "Iteration 71, loss = 0.00571136\n",
            "Iteration 72, loss = 0.00573277\n",
            "Iteration 73, loss = 0.00586208\n",
            "Iteration 74, loss = 0.00550514\n",
            "Iteration 75, loss = 0.00550050\n",
            "Iteration 76, loss = 0.00567975\n",
            "Iteration 77, loss = 0.00537211\n",
            "Iteration 78, loss = 0.00560265\n",
            "Iteration 79, loss = 0.00534226\n",
            "Iteration 80, loss = 0.00524449\n",
            "Iteration 81, loss = 0.00515640\n",
            "Iteration 82, loss = 0.00510060\n",
            "Iteration 83, loss = 0.00501970\n",
            "Iteration 84, loss = 0.00495815\n",
            "Iteration 85, loss = 0.00495713\n",
            "Iteration 86, loss = 0.00493942\n",
            "Iteration 87, loss = 0.00498842\n",
            "Iteration 88, loss = 0.00494938\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.1, max_fun=15000, max_iter=100, momentum=0.9,\n",
              "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "              random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
              "              validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFBQCovJu7yP",
        "outputId": "214a7881-29f7-408c-9215-f14fca6a9670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# RECOMMMEND\n",
        "# Performance of model\n",
        "\n",
        "print(\"Training set score: {0}\".format(mlp.score(X_train, y_train)))\n",
        "print()\n",
        "print(\"Test set score: {0}\".format(mlp.score(X_test, y_test)))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 1.0\n",
            "\n",
            "Test set score: 0.9777777777777777\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}